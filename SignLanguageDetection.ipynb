{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEbEpEWH5GQe"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LVHjI55cHIZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import img_to_array, load_img, array_to_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
        "from keras.applications.vgg16 import decode_predictions as decode_vgg\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUJpKA8dcHIc"
      },
      "source": [
        "# Mounting Google Drive\n",
        "- This code will mount my google drive on Colab.\n",
        "- We upload the data on our drive then we mount it in Colab to avoid loading process again and again.\n",
        "- It is helpful if Google Colab is used, not required if the code is run on Anaconda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6an241M6cHIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe36a2d-880c-4094-e201-2a643c20b111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EdCVdQQcHIc"
      },
      "source": [
        "# The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import img_to_array\n",
        "dataloc='/content/gdrive/MyDrive/Dataset/PSL'\n",
        "idg=ImageDataGenerator()\n",
        "data=idg.flow_from_directory(dataloc,target_size=(200,200),batch_size=100)\n",
        "print(data.num_classes)\n",
        "arrayimage=img_to_array(data)\n",
        "print(arrayimage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Qj6JWi69uZ",
        "outputId": "5edcac6b-1bbb-4230-e422-16bedf025cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1509 images belonging to 37 classes.\n",
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Visualization**"
      ],
      "metadata": {
        "id": "EaClNtqLm_8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot Ain ع': 0 photos from the SLD dataset\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "# define location of dataset\n",
        "folder = \"/content/gdrive/MyDrive/Dataset/PSL/Ain ع/\"\n",
        "# plot first few images\n",
        "for i in range(1,10):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(3, 3, i)\n",
        "\t# define filename\n",
        "\tfilename = folder + 'W_' + str(i) + '.png' # cat.0.jpg , cat.1.jpg , cat.2.jpg\n",
        "\t# load image pixels\n",
        "\timage = imread(filename)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "Jh_fSemjnD9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot Ain ع': 0 photos from the SLD dataset\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "# define location of dataset\n",
        "folder = \"/content/gdrive/MyDrive/Dataset/PSL/Tay ت/\"\n",
        "# plot first few images\n",
        "for i in range(1,10):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(3, 3, i)\n",
        "\t# define filename\n",
        "\tfilename = folder + 'D_' + str(i) + '.png' # cat.0.jpg , cat.1.jpg , cat.2.jpg\n",
        "\t# load image pixels\n",
        "\timage = imread(filename)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "gOEaVuG8pts_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Converting Images to Array**"
      ],
      "metadata": {
        "id": "FyWsoZdFCgXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import img_to_array, load_img, array_to_img\n",
        "x = img_to_array(data) #Converting the PIL.Image.Image type to a 3D tensor with shape (224, 224, 3)\n",
        "x"
      ],
      "metadata": {
        "id": "1n6Inyh-ClO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Preprocessing**"
      ],
      "metadata": {
        "id": "Puu39C8kqj2W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QUictsTjkoG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDO4qj9ccHId"
      },
      "source": [
        "### Creating 4D tensor of all images and setting labels for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR8aiehOcHId"
      },
      "outputs": [],
      "source": [
        "#This method  two arrays:\n",
        "#the first one contains the list of all filenames, and\n",
        "#the second one contains the list of all corresponding labels\n",
        "%%time\n",
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    paths = np.array(data['filenames'])\n",
        "    targets = np_utils.to_categorical(np.array(data['target']))\n",
        "    return paths, targets\n",
        "\n",
        "files, targets = load_dataset('/content/gdrive/MyDrive/Dataset/PSL')\n",
        "\n",
        "#This method loads an image, converts it to binary, and then adds a dimension to it.\n",
        "def path_to_tensor(img_path):\n",
        "    img = load_img(img_path, target_size=(224, 224)) #Loading an RGB image as PIL.Image.Image type\n",
        "    x = img_to_array(img) #Converting the PIL.Image.Image type to a 3D tensor with shape (224, 224, 3)\n",
        "    return np.expand_dims(x, axis=0) #Converting the 3D tensor to a 4D tensor with shape (1, 224, 224, 3) and returns the 4D tensor\n",
        "\n",
        "#This method returns a 4D tensor of all images in binary form\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
        "    return np.vstack(list_of_tensors)\n",
        "\n",
        "image_tensors = paths_to_tensor(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK-DdZL_cHId"
      },
      "outputs": [],
      "source": [
        "#Tensor of images\n",
        "image_tensors\n",
        "image_tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZvwtFfXcHIf"
      },
      "outputs": [],
      "source": [
        "#The varaible 'target' contains two separate values for each pinture.\n",
        "#First value shows if it is a cat (Class_a), and the second value shows if it is a dog (Class_b).\n",
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6vWkD2xcHIh"
      },
      "outputs": [],
      "source": [
        "#Converting 'targets into one-valued array 'target'\n",
        "single_target=[]\n",
        "\n",
        "for i in targets: #Label 0 is cat and 1 is dog\n",
        "    if i[0]==0.:\n",
        "        single_target.append(1) #for cat\n",
        "    else:\n",
        "        single_target.append(0) #for dog\n",
        "#target=np.array(single_target).reshape(-1,1)\n",
        "target=np.array(single_target)\n",
        "target\n",
        "#target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Lr8EZ9cHIi"
      },
      "source": [
        "### Checking out some random images for verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLr3wZMPcHIi"
      },
      "outputs": [],
      "source": [
        "img_no=30\n",
        "display(array_to_img(image_tensors[img_no]))\n",
        "\n",
        "if target[img_no]==0:\n",
        "    print('A cat')\n",
        "else:\n",
        "    print('A dog')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f9fOUtecHIj"
      },
      "source": [
        "### Preprocessing the images as per requirement of the VGG model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo1F9dfecHIj"
      },
      "outputs": [],
      "source": [
        "images = preprocess_input_vgg(image_tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAWlR8ofcHIj"
      },
      "source": [
        "- Now 'images' contains the preprocessed 4D tensor of images and 'target' contains the corrresponding labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Infbz-cHIk"
      },
      "source": [
        "### Spliting into train, valid and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjFOguRncHIk"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(images, target,test_size=0.1,random_state=0)\n",
        "X_train,X_valid,Y_train,Y_valid = train_test_split(X_train, Y_train,test_size=0.2,random_state=0)\n",
        "print('Shape of X_train:', X_train.shape)\n",
        "print('Shape of Y_train:', Y_train.shape)\n",
        "print('Shape of X_valid:', X_valid.shape)\n",
        "print('Shape of Y_valid:', Y_valid.shape)\n",
        "print('Shape of X_test:', X_test.shape)\n",
        "print('Shape of Y_test:', Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP34omGTcHIk"
      },
      "source": [
        "# Case 1: Using a pre-trained network as classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIuPH56ucHIk"
      },
      "source": [
        "### Downloading the model and its pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-lRP7slcHIl"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "vgg_case1 = VGG16(weights = \"imagenet\", input_shape = (224,224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_rSf9N_cHIl"
      },
      "outputs": [],
      "source": [
        "vgg_case1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cjJKxpFcHIl"
      },
      "source": [
        "### Making Prediction on an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svOT6-8pcHIl"
      },
      "outputs": [],
      "source": [
        "img_no=0\n",
        "\n",
        "display(array_to_img(image_tensors[img_no]))\n",
        "\n",
        "selected_img=np.expand_dims(images[img_no], axis=0)\n",
        "#Predicting the probability across all output classes\n",
        "prediction_vgg_case1 = vgg_case1.predict(selected_img)\n",
        "prediction_vgg_case1\n",
        "\n",
        "#Converting the probabilities to class labels\n",
        "labels=decode_vgg(prediction_vgg_case1)\n",
        "labels\n",
        "\n",
        "#Retrieving the most likely result with the highest probability\n",
        "#labels[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTVCFkmQcHIm"
      },
      "source": [
        "### Evaluating the model\n",
        "- We cannot evaluate the model here as VGG classifer supports 1000 classes, while our Y_test has only 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyY4B9MjcHIm"
      },
      "source": [
        "# Case 2: Using a pre-trained network as feature extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yzwJcBjcHIm"
      },
      "source": [
        "### Downloading the model without the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7HqgXcVcHIm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "vgg_case2 = VGG16(weights = \"imagenet\", include_top=False, input_shape = (224,224, 3))\n",
        "#include_top is false to ignore the fully connected classifier part on top of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGu8NNV_cHIn"
      },
      "outputs": [],
      "source": [
        "vgg_case2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DJAAAY5cHIn"
      },
      "source": [
        "### Freezing the feature extraction layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puyUG8k5cHIn"
      },
      "outputs": [],
      "source": [
        "for layer in vgg_case2.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tbCsyn2cHIn"
      },
      "outputs": [],
      "source": [
        "vgg_case2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euVMwOZqcHIo"
      },
      "source": [
        "### Adding our custom classfiier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6MhPhg6cHIo"
      },
      "outputs": [],
      "source": [
        "last_layer_case2 = vgg_case2.get_layer('block5_pool') #Saving the last layer of the network\n",
        "\n",
        "last_output_case2 = last_layer_case2.output #Saving the output of the last layer to be the input of the next layer\n",
        "\n",
        "x1 = Flatten()(last_output_case2) #Flattenning the classifier input, which is the output of the last layer of the VGG16 model\n",
        "x1 = Dense(64, activation='relu', name='FC_2')(x1) #Adding 1 dense layer of 64 neurons\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Dropout(0.5)(x1)\n",
        "x1 = Dense(1, activation='sigmoid', name='sigmoid')(x1) #Adding our new softmax layer with two hidden units\n",
        "#x1 = Dense(2, activation='softmax', name='softmax')(x1) #Adding our new softmax layer with two hidden units\n",
        "\n",
        "model_vgg_case2 = Model(inputs=vgg_case2.input, outputs=x1) #Instantiating a new_model\n",
        "\n",
        "model_vgg_case2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFTdaH9ccHIo"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT4Lnmr-cHIo"
      },
      "outputs": [],
      "source": [
        "model_vgg_case2.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpjrWj2ocHIo"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3OuCPo0cHIp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_vgg_case2.fit(X_train, Y_train, batch_size=10, epochs=20, verbose=0, validation_data=(X_valid, Y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCTYd9wBcHIp"
      },
      "source": [
        "### Making Prediction on the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB5rVRNqcHIu"
      },
      "outputs": [],
      "source": [
        "img_no=0\n",
        "display(array_to_img(image_tensors[img_no]))\n",
        "\n",
        "selected_img=np.expand_dims(images[img_no], axis=0)\n",
        "\n",
        "prediction_vgg_case2 = model_vgg_case2.predict(selected_img)\n",
        "print(round(prediction_vgg_case2[0][0]*100,2),'% probability that the image contains a dog')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nJp59v1cHIv"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0hmx_2QcHIv"
      },
      "outputs": [],
      "source": [
        "print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*model_vgg_case2.evaluate(X_test, Y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdrwG6OGcHIw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os92za8OcHIx"
      },
      "source": [
        "# Case 3: Using a pre-trained with fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHDl4yrgcHIx"
      },
      "source": [
        "### Downloading the model without the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ymRhmRucHIx"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "vgg_case3 = VGG16(weights = \"imagenet\", include_top=False, input_shape = (224,224, 3))\n",
        "#include_top is false to ignore the fully connected classifier part on top of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiGknOmBcHIx"
      },
      "outputs": [],
      "source": [
        "vgg_case3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_vQQ0YacHIy"
      },
      "source": [
        "### Freezing the feature extraction layers, leaving last 5 layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaPYnpoYcHIy"
      },
      "outputs": [],
      "source": [
        "for layer in vgg_case3.layers[:-5]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpAagShocHIy"
      },
      "outputs": [],
      "source": [
        "vgg_case3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBrPWAq6cHIz"
      },
      "source": [
        "### Adding our custom classfiier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QOjNw0gcHIz"
      },
      "outputs": [],
      "source": [
        "last_layer_case3 = vgg_case3.get_layer('block5_pool') #Saving the last layer of the network\n",
        "\n",
        "last_output_case3 = last_layer_case3.output #Saving the output of the last layer to be the input of the next layer\n",
        "\n",
        "x2 = Flatten()(last_output_case3) #Flattenning the classifier input, which is the output of the last layer of the VGG16 model\n",
        "x2 = Dense(64, activation='relu', name='FC_2')(x2) #Adding 1 dense layer of 64 neurons\n",
        "x2 = BatchNormalization()(x2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(1, activation='sigmoid', name='sigmoid')(x2) #Adding our new softmax layer with two hidden units\n",
        "#x2 = Dense(2, activation='softmax', name='softmax')(x2) #Adding our new softmax layer with two hidden units\n",
        "\n",
        "model_vgg_case3 = Model(inputs=vgg_case3.input, outputs=x2) #Instantiating a new_model\n",
        "\n",
        "model_vgg_case3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhhxifs-cHIz"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA1nfcQFcHIz"
      },
      "outputs": [],
      "source": [
        "model_vgg_case3.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzl3WrR3cHI0"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDjMEkc_cHI1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model_vgg_case3.fit(X_train, Y_train, batch_size=10, epochs=20, verbose=0, validation_data=(X_valid, Y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CokUsthDcHI1"
      },
      "source": [
        "### Making Prediction on the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqB9mB12cHI2"
      },
      "outputs": [],
      "source": [
        "img_no=0\n",
        "display(array_to_img(image_tensors[img_no]))\n",
        "\n",
        "selected_img=np.expand_dims(images[img_no], axis=0)\n",
        "#Predicting the probability across all output classes\n",
        "prediction_vgg_case3 = model_vgg_case3.predict(selected_img)\n",
        "prediction_vgg_case3\n",
        "\n",
        "#Converting the probabilities to class labels\n",
        "labels=decode_vgg(prediction_vgg_case3)\n",
        "labels\n",
        "\n",
        "#Retrieving the most likely result with the highest probability\n",
        "#labels[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSttyi68cHI2"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBWT6hsVcHI3"
      },
      "outputs": [],
      "source": [
        "print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*model_vgg_case3.evaluate(X_test, Y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkHv5ABbcHI3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}